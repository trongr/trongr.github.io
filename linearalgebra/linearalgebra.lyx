#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "ccfonts" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 12
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\rank}{\operatorname{rank}}
{rank}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\Var}{\operatorname{Var}}
{Var}
\end_inset


\end_layout

\begin_layout Title
Linear Algebra
\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Section
Theorem 2.23.
 Change of coordinates: conjugation by change of coordinate matrix.
\end_layout

\begin_layout Standard

\emph on
Let 
\begin_inset Formula $TnV,$
\end_inset

 
\begin_inset Formula $\beta,\gamma$
\end_inset

 be ordered bases for V.
 Suppose that 
\begin_inset Formula $Q=I_{\gamma}^{\beta}$
\end_inset

 is the change of coordinate matrix that changes 
\begin_inset Formula $\gamma$
\end_inset

 coordinates to 
\begin_inset Formula $\beta$
\end_inset

 coordinates.
 Then 
\begin_inset Formula 
\[
\left[T\right]_{\gamma}=Q^{-1}\left[T\right]_{\beta}Q.
\]

\end_inset


\end_layout

\begin_layout Section
Corollary 2.23.
 Representing a matrix in a different basis / change of coordinate matrix.
\end_layout

\begin_layout Standard

\emph on
Let 
\begin_inset Formula $A\in M_{n\times n}(F),$
\end_inset

 and let 
\begin_inset Formula $\gamma$
\end_inset

 be an ordered basis for 
\begin_inset Formula $F^{n}.$
\end_inset

 Then 
\begin_inset Formula $\left[L_{A}\right]_{\gamma}=Q^{-1}AQ,$
\end_inset

 where Q is the 
\begin_inset Formula $n\times n$
\end_inset

 matrix whose jth column is the jth vector of 
\begin_inset Formula $\gamma.$
\end_inset

 
\end_layout

\begin_layout Standard
Trivial example: 
\begin_inset Formula $\left[L_{A}\right]_{\beta}=I^{-1}AI=A,$
\end_inset

 where 
\begin_inset Formula $\beta$
\end_inset

 is the standard ordered basis for 
\begin_inset Formula $F^{n}.$
\end_inset

 
\end_layout

\begin_layout Standard
Given a 
\begin_inset Formula $\gamma,$
\end_inset

 we can define a map 
\begin_inset Formula $\Gamma:M_{n\times n}(F)\longrightarrow M_{n\times n}(F)$
\end_inset

 given by 
\begin_inset Formula 
\[
\Gamma:A\longmapsto\left[L_{A}\right]_{\gamma}=Q^{-1}AQ.
\]

\end_inset

What can we say about this map? Does it preserve properties of A and 
\begin_inset Formula $M_{n\times n}(F)?$
\end_inset

 First of all, is this a linear transformation? Yes:
\begin_inset Formula 
\[
\Gamma(aA+B)=Q^{-1}(aA+B)Q=aQ^{-1}AQ+Q^{-1}BQ=a\Gamma(A)+\Gamma(B).
\]

\end_inset


\end_layout

\begin_layout Standard
Note that 
\begin_inset Formula $\Gamma$
\end_inset

 maps operator to operator, not vectors in V.
\end_layout

\begin_layout Section
Intuition.
 Change of coordinates
\end_layout

\begin_layout Standard
Change of coordinates basically maps each vector in the original basis to
 a vector in the new basis.
 Each matrix in the original space V is mapped to a new vector in the same
 space V, but we should think of it really as a new space.
\end_layout

\begin_layout Section
Definition 2.23.
 Similar matrices
\end_layout

\begin_layout Standard

\emph on
Let A and B be matrices in 
\begin_inset Formula $M_{n\times n}(F^{n}).$
\end_inset

 We say that B is similar to A if there exists an invertible matrix Q s.t.
 
\begin_inset Formula $B=Q^{-1}AQ.$
\end_inset

 
\end_layout

\begin_layout Section
Theorem 2.3.
 Rank nullity theorem / Dimension theorem
\end_layout

\begin_layout Standard

\emph on
Let V be a finite dimensional vector space, and W be a (not necessarily
 finite dimensional) vector space over some field and let 
\begin_inset Formula $T:V\longrightarrow W$
\end_inset

 be a linear map.
 Then
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\operatorname{dim}(\operatorname{im}(T))+\operatorname{dim}(\operatorname{ker}(T))=\operatorname{dim}(V)
\]

\end_inset


\end_layout

\begin_layout Section
Theorem 6.1.
 Properties of inner products
\end_layout

\begin_layout Standard

\emph on
Let 
\begin_inset Formula $V.$
\end_inset

 If
\emph default
 
\begin_inset Formula $\left\langle x,y\right\rangle =\left\langle x,z\right\rangle $
\end_inset

 
\emph on
for all 
\begin_inset Formula $x,$
\end_inset

 then 
\begin_inset Formula $y=z.$
\end_inset

 Similarly 
\begin_inset Formula $\left\langle y,x\right\rangle =\left\langle z,x\right\rangle .$
\end_inset

 
\end_layout

\begin_layout Section
Exercise 5.4.25.
 
\emph on
Simultaneously diagonalizable if 
\emph default

\begin_inset Formula $UT=TU$
\end_inset


\end_layout

\begin_layout Standard
Proposition
\emph on
.
 If T and U are diagonalizable linear operators on a finite-dimensional
 vector space V s.t.
 
\begin_inset Formula $UT=TU,$
\end_inset

 then T and U are simultaneously diagonalizable.
\end_layout

\begin_layout Section
Theorem.
 
\emph on
If two operators agree on a basis, they are equal.
\end_layout

\begin_layout Section
Schur's Theorem 6.14.
 Splitting characteristic polynomial and orthonormal basis s.t.
 
\begin_inset Formula $[T]_{\beta}$
\end_inset

 upper triangular.
\end_layout

\begin_layout Standard

\emph on
Let TnV.
 Suppose that the characteristic polynomial of T splits.
 Then there exists an orthonormal basis 
\begin_inset Formula $\beta$
\end_inset

 for V s.t.
 
\begin_inset Formula $[T]_{\beta}$
\end_inset

 is upper triangular.
\end_layout

\begin_layout Section
Def.
 Normal operators
\end_layout

\begin_layout Standard

\emph on
Let 
\begin_inset Formula $A:V\longrightarrow V$
\end_inset

.
 Then A is normal iff it commutes with its adjoint: 
\begin_inset Formula $AA^{*}=A^{*}A.$
\end_inset


\end_layout

\begin_layout Section
E.g.
 of normal operators: unitary, selfadjoint, and real symmetric operators
\end_layout

\begin_layout Standard
Unitary operators are normal: 
\begin_inset Formula $A^{*}=A^{-1},$
\end_inset

 which commutes with A.
 Selfadjoint [and therefore real symmetric] operators are normal: 
\begin_inset Formula $A^{*}=A.$
\end_inset

 
\end_layout

\begin_layout Section
Theorem 6.15.
 
\emph on
Eigenvectors corresponding to distinct eigenvalues of a normal operator
 are orthogonal
\end_layout

\begin_layout Standard
Theorem.
 
\emph on
Let T be normal on V, 
\begin_inset Formula $\left\langle \cdot,\cdot\right\rangle .$
\end_inset

 Then eigenvectors corresponding to distinct eigenvalues of T are orthogonal.
\end_layout

\begin_layout Section
Definition.
 Adjoint operators
\end_layout

\begin_layout Standard
are also called Hermitian adjoint, Hermitian conjugate or Hermitian transpose.
\end_layout

\begin_layout Standard

\emph on
Let 
\begin_inset Formula $A:V\longrightarrow W$
\end_inset

 be linear.
 Then the adjoint of A is the unique linear operator 
\begin_inset Formula $A^{*}:W\longrightarrow V$
\end_inset

 s.t.
 
\begin_inset Formula 
\[
\left\langle Av,w\right\rangle _{W}=\left\langle v,A^{*}w\right\rangle _{V}.
\]

\end_inset


\end_layout

\begin_layout Standard
Existence and uniqueness to be proved.
\end_layout

\begin_layout Section
Theorem.
 
\emph on
Normal operators are diagonalizable
\end_layout

\begin_layout Section
Theorem *6.3.
 
\emph on
An operator T is diagonalizable iff there exists a basis of V consisting
 of eigenvectors of T
\end_layout

\begin_layout Standard

\emph on
Corollary.
 If T is a selfadjoint operator, then there is a basis of V consisting of
 eigenvectors of T.
\end_layout

\begin_layout Standard

\emph on
Proof.
 
\emph default
Follows from Theorem 6.16 or 6.17.
\end_layout

\begin_layout Section
Theorem 6.3.
 Representing a vector as a linear combination of orthogonal vectors using
 inner product projections
\end_layout

\begin_layout Standard

\emph on
Theorem.
 Let V be an inner product space and 
\begin_inset Formula $S=\left\{ v_{1},v_{2}\dots\ldots,v_{k}\right\} $
\end_inset

 be an orthogonal subset of V consisting of nonzero vectors.
 If 
\begin_inset Formula $y\in\operatorname{span}(S)$
\end_inset

 then 
\begin_inset Formula 
\[
y=\sum_{i=1}^{k}\frac{\left\langle y,v_{i}\right\rangle }{\|v_{i}\|^{2}}v_{i}.
\]

\end_inset


\end_layout

\begin_layout Standard
Corollary.
 
\emph on
Let V be an inner product space and 
\begin_inset Formula $S=\left\{ v_{1},v_{2}\dots\ldots,v_{k}\right\} $
\end_inset

 be an orthonormal subset of V and 
\begin_inset Formula $y\in\operatorname{span}(S),$
\end_inset

 then 
\begin_inset Formula 
\[
y=\sum_{i=1}^{k}\left\langle y,v_{i}\right\rangle v_{i}.
\]

\end_inset


\end_layout

\begin_layout Standard
Corollary.
 
\emph on
Let V be an inner product space, 
\begin_inset Formula $y\in V,$
\end_inset

 and 
\begin_inset Formula $\beta=\left\{ v_{1},v_{2}\dots\ldots,v_{k}\right\} $
\end_inset

 be an orthonormal basis for V.
 Then 
\begin_inset Formula 
\[
y=\sum_{i=1}^{k}\left\langle y,v_{i}\right\rangle v_{i}.
\]

\end_inset


\end_layout

\begin_layout Section
Theorem 6.10.
 Matrix of the adjoint and adjoint of the matrix under orthonormal basis
\end_layout

\begin_layout Standard

\emph on
Let 
\begin_inset Formula $TVn\beta$
\end_inset

 be orthonormal.
 Then 
\begin_inset Formula $[T^{*}]_{\beta}=\left[T\right]_{\beta}^{*}.$
\end_inset


\end_layout

\begin_layout Section
Corollary 6.10.
 Matrix version
\end_layout

\begin_layout Standard

\emph on
Let A by an n by n matrix.
 Then 
\begin_inset Formula $L_{A^{*}}=(L_{A})^{*}.$
\end_inset


\end_layout

\begin_layout Section
Theorem 6.16.
 Complex case: normal operator and orthonormal basis consisting of eigenvectors
\end_layout

\begin_layout Standard

\emph on
Let T be a linear operator on a finite-dimensional complex inner product
 space V.
 Then T is normal iff there exists an orthonormal basis for V consisting
 of eigenvectors of T.
\end_layout

\begin_layout Section
Theorem 6.17.
 Real case: self-adjoint operator and orthonormal basis consisting of eigenvecto
rs
\end_layout

\begin_layout Standard

\emph on
Let T be a linear operator on a finite-dimensional real inner product space
 V.
 Then T is self-adjoint iff there exists an orthonormal basis for V consisting
 of eigenvectors of T.
\end_layout

\begin_layout Standard
Note that a real selfadjoint matrix is symmetric, 
\begin_inset Formula $A^{*}=A^{T}=A.$
\end_inset

 
\end_layout

\begin_layout Section
Corollary 6.17.
 Normal / selfadjoint implies diagonalizable
\end_layout

\begin_layout Standard

\emph on
Let T be a linear operator on a finite-dimensional complex [real] inner
 product space V.
 If T is normal [self-adjoint] then T is diagonalizable.
\end_layout

\begin_layout Standard

\emph on
Proof.
 
\emph default
In either case, V has an orthonormal basis consisting of eigenvectors of
 T.
 By Theorem *6.3, this happens iff T is diagonalizable.
 Oh, I already have this corollary as a corollary over there.
\end_layout

\begin_layout Section
Summary of normality V.S.
 diagonalizability
\end_layout

\begin_layout Standard
We have 
\begin_inset Formula 
\begin{align*}
\text{Normal / selfadjoint\iff} & \text{Exists orthonormal eigenbasis}\\
\implies & \text{Exists eigenbasis }\\
\iff & \text{Diagonalizable.}
\end{align*}

\end_inset

and it seems that the two are not equivalent.
 QUESTION.
 Are there diagonalizable operators that aren't normal / selfadjoint? We
 just need to find one that has an eigenbasis that isn't orthonormal, How?
\end_layout

\begin_layout Section
TODO.
 Example of diagonalizable operator that isn't normal/selfadjoint
\end_layout

\begin_layout Section
Example of a complex symmetric matrix that isn't normal
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula 
\[
A=\begin{bmatrix}1 & i\\
i & -1
\end{bmatrix}.
\]

\end_inset

Then A is symmetric complex, but isn't normal, because it is not diagonalizable
 [TODO.
 Show this].
 If it were normal, then it would be diagonalizable by Corollary 6.17.
\end_layout

\begin_layout Section

\series bold
Proposition.

\series default
 Eigenvectors and eigenvalues of the adjoint of a normal operator
\end_layout

\begin_layout Standard

\series bold
Proposition.
 
\series default
\emph on
Let T be a normal linear operator on an inner product space V with eigenvalue
 
\begin_inset Formula $\text{\lambda}$
\end_inset

 and eigenvector 
\begin_inset Formula $x,$
\end_inset

 then 
\begin_inset Formula $x$
\end_inset

 is an eigenvector of 
\begin_inset Formula $T^{*}$
\end_inset

 corresponding to eigenvalue 
\begin_inset Formula $\overline{\lambda}.$
\end_inset


\end_layout

\begin_layout Section
Conjecture.
 
\emph on
The inner product is unique up to an orthonormal basis.
 
\end_layout

\begin_layout Standard

\emph on
Specifically, let V be a finite-dimensional inner product on C or R, and
 
\begin_inset Formula $\beta$
\end_inset

 and 
\begin_inset Formula $\gamma$
\end_inset

 be any orthonormal bases for V, and x, y be vectors in V.
 Then 
\begin_inset Formula 
\[
\left\langle x,y\right\rangle =\overline{y}^{T}x=[y]_{\beta}\cdot[x]_{\beta}=[y]_{\gamma}\cdot[x]_{\gamma}.
\]

\end_inset

In other words, the dot product of two vectors is the same in any orthonormal
 basis.
\end_layout

\begin_layout Standard
Proof.
 TODO.
\end_layout

\begin_layout Standard
Definition.
 
\emph on
A linear operator 
\begin_inset Formula $T$
\end_inset

 on a finite dimensional inner product space V is called positive definite
 if T is self-adjoint and 
\begin_inset Formula $\left\langle T(x),x\right\rangle >0$
\end_inset

 for all 
\begin_inset Formula $x\neq0.$
\end_inset

 It's called positive semidefinite if 
\begin_inset Formula $\left\langle T(x),x\right\rangle \geq0$
\end_inset

 for all 
\begin_inset Formula $x\neq0.$
\end_inset

 Similarly for a square matrix 
\begin_inset Formula $A.$
\end_inset


\end_layout

\begin_layout Section
Exercise 6.4.17.
 Positive semi/definite operator
\end_layout

\begin_layout Standard

\emph on
Let T and U be self-adjoint linear operators on an n-dimensional inner product
 space V, and let 
\begin_inset Formula $A=\left[T\right]_{\beta},$
\end_inset

 where 
\begin_inset Formula $\beta$
\end_inset

 is an orthonormal basis for V.
 Prove:
\end_layout

\begin_layout Enumerate

\emph on
T is positive definite (semidefinite) iff all of its eigenvalues are positive
 (nonnegative).
\end_layout

\begin_layout Enumerate

\emph on
T is positive definite iff 
\begin_inset Formula 
\[
\sum_{i,j}A_{ij}a_{j}\overline{a}_{i}>0
\]

\end_inset

for all 
\begin_inset Formula $(a_{1},\ldots,a_{n})\neq0.$
\end_inset

 [What about semidefinite? Also true.]
\end_layout

\begin_layout Enumerate

\emph on
T is positive semidefinite iff 
\begin_inset Formula $A=B^{*}B$
\end_inset

 for some square matrix B.
\end_layout

\begin_layout Enumerate

\emph on
If T and U are positive semidefinite operators s.t.
 
\begin_inset Formula $T^{2}=U^{2},$
\end_inset

 then 
\begin_inset Formula $T=U.$
\end_inset


\end_layout

\begin_layout Enumerate

\emph on
If T and U are positive definite (semidefinite?) operators s.t.
 
\begin_inset Formula $TU=UT,$
\end_inset

 then 
\begin_inset Formula $TU$
\end_inset

 is positive definite (semidefinite?).
\end_layout

\begin_layout Enumerate

\emph on
T is positive definite (semidefinite) iff A is.
\end_layout

\begin_layout Standard

\emph on
Proof 1.
 
\emph default
We'll show definite, semi is similar.
 Let T be positive definite, and let 
\begin_inset Formula $\lambda$
\end_inset

 be an eigenvalue, and 
\begin_inset Formula $x\neq0.$
\end_inset

 Then 
\begin_inset Formula 
\begin{align*}
\left\langle T(x),x\right\rangle  & >0\\
\left\langle \lambda x,x\right\rangle  & >\\
\lambda\left\langle x,x\right\rangle  & >\\
\lambda\text{\left|x\right|}^{2} & >0.
\end{align*}

\end_inset

Since 
\begin_inset Formula $\text{\left|x\right|}>0,$
\end_inset

 
\begin_inset Formula $\lambda$
\end_inset

 must also be 
\begin_inset Formula $>0.$
\end_inset

 Conversely, suppose that all eigenvalues of T are positive.
 Let 
\begin_inset Formula $v_{i}$
\end_inset

 be the eigenvectors of T with corresponding eigenvalues 
\begin_inset Formula $\lambda_{i}$
\end_inset

.
 Then 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
T(v_{i})=\lambda_{i}v_{i}.
\]

\end_inset

Now let 
\begin_inset Formula $x$
\end_inset

 be any vector, and 
\begin_inset Formula $x=\sum a_{i}v_{i}.$
\end_inset

 Then 
\begin_inset Formula 
\[
\left\langle T(x),x\right\rangle =\left\langle T\left(\sum a_{i}v_{i}\right),\sum a_{i}v_{i}\right\rangle =\left\langle \sum a_{i}\lambda_{i}v_{i},\sum a_{i}v_{i}\right\rangle =\sum\lambda_{i}\left|v_{i}\right|^{2}
\]

\end_inset

(because the 
\begin_inset Formula $v_{i}$
\end_inset

's are orthonormal).
\end_layout

\begin_layout Standard

\emph on
Proof 2.
 
\emph default
First note that
\begin_inset Formula 
\[
\sum_{i,j}A_{ij}a_{j}\overline{a}_{i}=\text{\ensuremath{\overline{a}^{T}Aa=\overline{\begin{bmatrix}a_{1} & \cdots & a_{n}\end{bmatrix}}\left[A_{ij}\right]\begin{bmatrix}a_{1}\\
\vdots\\
a_{n}
\end{bmatrix}.}}
\]

\end_inset

This is equal to 
\begin_inset Formula 
\[
\left\langle T\left(x\right),x\right\rangle 
\]

\end_inset

since 
\begin_inset Formula $\beta$
\end_inset

 is an orthonormal basis (recall that 
\emph on
the dot product of two vectors is the same in any orthonormal basis
\emph default
).
\end_layout

\begin_layout Section
Ex 6.4.18.
 Derived positive semidefinite matrices
\end_layout

\begin_layout Standard

\emph on
Let 
\begin_inset Formula $T:V\longrightarrow W$
\end_inset

 be a linear transformation, where V and W are finite-dim.
 Then
\end_layout

\begin_layout Enumerate
\begin_inset Formula $T^{*}T$
\end_inset

 and 
\begin_inset Formula $TT^{*}$
\end_inset

 are positive semidefinite.
\end_layout

\begin_layout Enumerate
\begin_inset Formula $\rank(T^{*}T)=\rank(TT^{*})=\rank(T).$
\end_inset


\end_layout

\begin_layout Section
Ex 6.4.19.
 Properties of positive definite operators
\end_layout

\begin_layout Standard

\emph on
Let T and U be positive definite operators on an inner product space V.
 Then
\end_layout

\begin_layout Enumerate
\begin_inset Formula $T+U$
\end_inset

 is positive definite.
\end_layout

\begin_layout Enumerate
If 
\begin_inset Formula $c>0,$
\end_inset

 then 
\begin_inset Formula $cT$
\end_inset

 is p.d.
\end_layout

\begin_layout Enumerate
\begin_inset Formula $T^{-1}$
\end_inset

 is p.d.
\end_layout

\begin_layout Section
Unitary and orthogonal operators and their matrices
\end_layout

\begin_layout Standard
Definition.
 
\emph on
Let T, n, 
\begin_inset Formula $\left\langle \right\rangle ,V,F.$
\end_inset

 If 
\begin_inset Formula $\left|\left|T(x)\right|\right|=\left|\left|x\right|\right|$
\end_inset

 for all 
\begin_inset Formula $x,$
\end_inset

 we call T a unitary operator if 
\begin_inset Formula $F=C,$
\end_inset

 and an orthogonal operator if 
\begin_inset Formula $F=R.$
\end_inset

 T is also called an isometry, or length-preserving operator.
\end_layout

\begin_layout Section
Example 6.18.
 Rotation in 
\begin_inset Formula $R^{2}.$
\end_inset

 
\end_layout

\begin_layout Standard
E.g.
 any rotation or reflection in 
\begin_inset Formula $R^{2}$
\end_inset

 preserves length and hence is an orthogonal operator.
 Rotation by 
\begin_inset Formula $\theta$
\end_inset

 given by 
\begin_inset Formula 
\[
R_{\theta}=\begin{bmatrix}\cos\theta & -\sin\theta\\
\sin\theta & \cos\theta
\end{bmatrix}.
\]

\end_inset

Rotation by 
\begin_inset Formula $-\theta$
\end_inset

 is its inverse:
\begin_inset Formula 
\[
R_{\theta}^{-1}=R_{-\theta}=\begin{bmatrix}\cos\theta & \sin\theta\\
-\sin\theta & \cos\theta
\end{bmatrix}=R_{\theta}^{T}.
\]

\end_inset

Since rotation by 
\begin_inset Formula $\theta$
\end_inset

 followed by rotation by 
\begin_inset Formula $-\theta$
\end_inset

 is the identity, we have
\begin_inset Formula 
\[
R_{\theta}^{T}R_{\theta}=R_{\theta}^{-1}R_{\theta}=I.
\]

\end_inset

By Theorem 6.18 below, 
\begin_inset Formula $R_{\theta}$
\end_inset

 is orthogonal.
 By Theorem 6.18.b, it preserves the inner product and hence preserves the
 angle between two vectors.
 By Corollary 6.18.1, its rows and columns form orthonormal bases for 
\begin_inset Formula $R^{2}.$
\end_inset

 Since 
\begin_inset Formula $R_{\theta}\neq R_{\theta}^{T}$
\end_inset

, it is not selfadjoint.
\end_layout

\begin_layout Standard
E.g.
 Recall the space H of continuous complex-valued functions defined on 
\begin_inset Formula $[0,2\pi]$
\end_inset

 with the inner product
\begin_inset Formula 
\[
\left\langle f,g\right\rangle =\frac{1}{2\pi}\int_{0}^{2\pi}f(t)\overline{g(t)}dt.
\]

\end_inset

 Let 
\begin_inset Formula $h\in H$
\end_inset

 satisfy 
\begin_inset Formula $\left|h(x)\right|=1$
\end_inset

 for all 
\begin_inset Formula $x.$
\end_inset

 Define T on H by 
\begin_inset Formula $T(f)=hf.$
\end_inset

 Then 
\begin_inset Formula 
\[
\left|\left|T(f)\right|\right|^{2}=\left|\left|hf\right|\right|^{2}=\frac{1}{2\pi}\int_{0}^{2\pi}h(t)f(t)\overline{h(t)f(t)}dt=\left|\left|f\right|\right|^{2}
\]

\end_inset

since 
\begin_inset Formula $\left|h(t)\right|^{2}=1.$
\end_inset

 So T is a unitary operator.
 
\end_layout

\begin_layout Section
Lemma 6.18.
 
\begin_inset Formula $T_{0}$
\end_inset

 is the only self-adjoint operator that is orthogonal to all its inputs
\end_layout

\begin_layout Standard

\emph on
Let U be self adjoint on 
\begin_inset Formula $n,\left\langle \right\rangle ,V.$
\end_inset

 If 
\begin_inset Formula $\left\langle x,U(x)\right\rangle =0$
\end_inset

 for all x, then 
\begin_inset Formula $U=T_{0},$
\end_inset

 the zero operator.
\end_layout

\begin_layout Standard

\emph on
Proof.
 
\emph default
By Theorem 6.16 or 6.17, there exists an orthonormal basis 
\begin_inset Formula $\beta$
\end_inset

 for V consisting of eigenvectors of U.
 Let 
\begin_inset Formula $x\in\beta.$
\end_inset

 Then 
\begin_inset Formula $U(x)=\lambda x$
\end_inset

 for some 
\begin_inset Formula $\lambda.$
\end_inset

 Thus
\begin_inset Formula 
\[
0=\left\langle x,U(x)\right\rangle =\left\langle x,\lambda x\right\rangle =\overline{\lambda}\left\langle x,x\right\rangle =\overline{\lambda}\left|\left|x\right|\right|^{2},
\]

\end_inset

and 
\begin_inset Formula $\overline{\lambda}=0.$
\end_inset

 Hence 
\begin_inset Formula $U(x)=0$
\end_inset

 for all 
\begin_inset Formula $x\in\beta$
\end_inset

 and 
\begin_inset Formula $U=T_{0}.$
\end_inset

 
\end_layout

\begin_layout Standard
Nonexample of a nonselfadjoint operator that has 
\begin_inset Formula $\left\langle x,U(x)\right\rangle =0$
\end_inset

 but is not the zero op: the rotation U by 90 degrees in the plane.
\end_layout

\begin_layout Section
Theorem 6.18.
 Characterizing unitary / orthogonal / isometric operators on a fin dim
 inner product space
\end_layout

\begin_layout Standard

\emph on
Let T, n, 
\begin_inset Formula $\left\langle \right\rangle ,V,F.$
\end_inset

 Then the following statements are equivalent:
\end_layout

\begin_layout Enumerate

\emph on
\begin_inset Formula $TT^{*}=T^{*}T=I.$
\end_inset

 In particular, T is normal and there exists an orthonormal basis for V
 consisting of eigenvectors of T.
\end_layout

\begin_layout Enumerate

\emph on
\begin_inset Formula $\left\langle T(x),T(y)\right\rangle =\left\langle x,y\right\rangle $
\end_inset

 for all 
\begin_inset Formula $x,y.$
\end_inset


\end_layout

\begin_layout Enumerate

\emph on
If 
\begin_inset Formula $\beta$
\end_inset

 is an orthonormal basis, then 
\begin_inset Formula $T(\beta)$
\end_inset

 is an orthonormal basis.
\end_layout

\begin_layout Enumerate

\emph on
There exists an orthonormal basis 
\begin_inset Formula $\beta$
\end_inset

 s.t.
 
\begin_inset Formula $T(\beta)$
\end_inset

 is an orthonormal basis.
\end_layout

\begin_layout Enumerate

\emph on
\begin_inset Formula $\left|\left|T(x)\right|\right|=\left|\left|x\right|\right|$
\end_inset

 for all 
\begin_inset Formula $x,$
\end_inset

 i.e.
 T is unitary / orthogonal.
\end_layout

\begin_layout Standard
In other words, an operator is unitary / orthogonal iff it is normal and
 its 
\begin_inset Quotes eld
\end_inset

norm
\begin_inset Quotes erd
\end_inset

 
\begin_inset Formula $TT^{*}$
\end_inset

 is 1.
\end_layout

\begin_layout Standard

\emph on
Proof
\emph default
 (1) implies (2).
 For any 
\begin_inset Formula $x,y,$
\end_inset

 
\begin_inset Formula 
\[
\left\langle x,y\right\rangle =\left\langle T^{*}T(x),y\right\rangle =\left\langle T(x),T(y)\right\rangle .
\]

\end_inset


\end_layout

\begin_layout Standard

\emph on
Proof 
\emph default
(2) implies (3).
 Let 
\begin_inset Formula $\beta=\left\{ v_{1},\ldots,v_{n}\right\} $
\end_inset

 be an orthonormal basis for V.
 Then 
\begin_inset Formula $T(\beta)=\left\{ T(v_{1}),\ldots,T(v_{n})\right\} $
\end_inset

 and 
\begin_inset Formula 
\[
\left\langle T(v_{i}),T(v_{j})\right\rangle =\left\langle v_{i},v_{j}\right\rangle =\delta_{ij},
\]

\end_inset

so 
\begin_inset Formula $T(\beta)$
\end_inset

 is an orthonormal basis for V.
\end_layout

\begin_layout Standard
Proof (3) implies (4).
 [This one is a little odd?] Any orthonormal basis 
\begin_inset Formula $\beta$
\end_inset

 satisfies this property, and there must be one because V is fin dim.
\end_layout

\begin_layout Standard
Proof (4) implies (5).
 Let 
\begin_inset Formula $x\in V,\beta=\left\{ v_{1},\ldots,v_{n}\right\} .$
\end_inset

 Then
\begin_inset Formula 
\[
x=\sum_{i=1}^{n}a_{i}v_{i}
\]

\end_inset

for some 
\begin_inset Formula $a_{i},$
\end_inset

 and 
\begin_inset Formula 
\[
\left|\left|x\right|\right|^{2}=\left\langle \sum_{i=1}^{n}a_{i}v_{i},\sum_{i=1}^{n}a_{i}v_{i}\right\rangle =\sum_{i}\sum_{j}a_{i}\overline{a_{j}}\left\langle v_{i},v_{j}\right\rangle =\sum_{i=1}^{n}\left|a_{i}\right|^{2}.
\]

\end_inset

Similarly,
\begin_inset Formula 
\[
\left|\left|T(x)\right|\right|^{2}=\left\langle \sum_{i=1}^{n}a_{i}T(v_{i}),\sum_{i=1}^{n}a_{i}T(v_{i})\right\rangle =\sum_{i}\sum_{j}a_{i}\overline{a_{j}}\left\langle T(v_{i}),T(v_{j})\right\rangle =\sum_{i=1}^{n}\left|a_{i}\right|^{2},
\]

\end_inset

since 
\begin_inset Formula $T(\beta)$
\end_inset

 is also orthonormal.
\end_layout

\begin_layout Standard
Proof (5) implies (1).
 For any 
\begin_inset Formula $x,$
\end_inset


\begin_inset Formula 
\[
\begin{aligned}\left\langle x,x\right\rangle  & =\left\langle T(x),T(x)\right\rangle =\left\langle x,T^{*}T(x)\right\rangle \\
\left\langle x,(I-T^{*}T)(x)\right\rangle  & =0.
\end{aligned}
\]

\end_inset

Let 
\begin_inset Formula $U=I-T^{*}T.$
\end_inset

 Then U is self-adjoint and 
\begin_inset Formula $\left\langle x,U(x)\right\rangle =0$
\end_inset

 for all x.
 By the previous lemma, 
\begin_inset Formula $I-T^{*}T=U=T_{0}$
\end_inset

 and 
\begin_inset Formula $I=T^{*}T.$
\end_inset

 [Why does this imply that 
\begin_inset Formula $TT^{*}=I?$
\end_inset

 The referenced Exercise 2.4.10 is about invertible matrices, not adjoint
 operators....
 Ah, See next.] 
\end_layout

\begin_layout Section
Corollary 6.18.0.
 
\emph on
The adjoint of a unitary / orthogonal operator is its inverse
\end_layout

\begin_layout Standard

\emph on
Proof.
 
\emph default
Suppose T is uni./orthog.
 Then 
\begin_inset Formula $TT^{*}=I,$
\end_inset

 hence 
\begin_inset Formula $T^{*}=T^{-1},$
\end_inset

 by Exercise 2.4.10.
\end_layout

\begin_layout Section
Proposition 6.18.0.
 T adjoint is T inverse iff T maps orthonormal basis to orthonormal basis.
\end_layout

\begin_layout Standard

\emph on
Let 
\begin_inset Formula $TnVF,$
\end_inset

 and let 
\begin_inset Formula $\beta$
\end_inset

 be an orthonormal basis for V, and suppose 
\begin_inset Formula $T^{-1}$
\end_inset

 exists.
 Then 
\begin_inset Formula $T^{*}=T^{-1}$
\end_inset

 iff 
\begin_inset Formula $T(\beta)$
\end_inset

 is also an orthonormal basis for V.
\end_layout

\begin_layout Standard
If that were true we can apply Exercise 2.4.10 and say that 
\begin_inset Formula $TT^{*}=TT^{-1}=I$
\end_inset

 and therefore 
\begin_inset Formula $T^{-1}T=T^{*}T=I.$
\end_inset

 
\end_layout

\begin_layout Standard
Proof.
 Suppose 
\begin_inset Formula $T^{*}=T^{-1}.$
\end_inset

 Then 
\begin_inset Formula $TT^{*}=T^{*}T=I$
\end_inset

 and (3) implies that 
\begin_inset Formula $T(\beta)$
\end_inset

 is an orthonormal basis.
 Conversely suppose that 
\begin_inset Formula $T(\beta)$
\end_inset

 is an orthonormal basis, 
\begin_inset Formula 
\[
\beta=\left\{ v_{1},\ldots,v_{n}\right\} ,T(\beta)=\left\{ T(v_{1}),\ldots,T(v_{n})\right\} .
\]

\end_inset

 To show that 
\begin_inset Formula $T^{*}=T^{-1},$
\end_inset

 we want to show that 
\begin_inset Formula 
\[
\left\langle T^{-1}(x),y\right\rangle =\left\langle T^{*}(x),y\right\rangle =\left\langle x,T(y)\right\rangle 
\]

\end_inset

for all 
\begin_inset Formula $x,y\in V.$
\end_inset

 It suffices to show that this holds for all 
\begin_inset Formula $x\in T(\beta),y\in\beta.$
\end_inset

 [Why? This feels right, but it's not quite the result I'm thinking about.]
 There are two cases: either (1) 
\begin_inset Formula $x=T(y)$
\end_inset

 or (2) 
\begin_inset Formula $x\neq T(y).$
\end_inset

 In case (1), 
\begin_inset Formula 
\[
\left\langle T^{-1}(x),y\right\rangle =\left\langle y,y\right\rangle =1=\left\langle x,T(y)\right\rangle .
\]

\end_inset

 In case (2), 
\begin_inset Formula 
\[
\left\langle x,T(y)\right\rangle =0=\left\langle T^{-1}(x),y\right\rangle .
\]

\end_inset

 Therefore 
\begin_inset Formula $T^{*}=T^{-1}.$
\end_inset

 
\end_layout

\begin_layout Section
Proposition.
 Equality of two operators in an inner product
\end_layout

\begin_layout Standard

\emph on
Let 
\begin_inset Formula $T,n\left\langle \right\rangle VF,$
\end_inset

 and let 
\begin_inset Formula $\beta$
\end_inset

 and 
\begin_inset Formula $T(\beta)$
\end_inset

 be orthonormal bases for V and suppose that 
\begin_inset Formula $T^{-1}$
\end_inset

 exists.
 If 
\begin_inset Formula 
\[
\left\langle T^{-1}(x),y\right\rangle =\left\langle x,T(y)\right\rangle 
\]

\end_inset

 for all 
\begin_inset Formula $y\in\beta,x\in T(\beta),$
\end_inset

 then 
\begin_inset Formula $\left\langle T^{-1}(x),y\right\rangle =\left\langle x,T(y)\right\rangle $
\end_inset

 for all 
\begin_inset Formula $x,y\in V.$
\end_inset

 In particular 
\begin_inset Formula $\left\langle T^{-1}(x),y\right\rangle =\left\langle T^{*}(x),y\right\rangle $
\end_inset

 for all x, y, and therefore 
\begin_inset Formula $T^{-1}=T^{*}.$
\end_inset

 
\end_layout

\begin_layout Standard
Proof.
 Let 
\begin_inset Formula $\beta=\left\{ v_{1},\ldots,v_{n}\right\} ,T(\beta)=\left\{ T(v_{1}),\ldots,T(v_{n})\right\} ,$
\end_inset

 and let 
\begin_inset Formula 
\begin{align*}
x & =\sum a_{i}T(v_{i})\\
y & =\sum b_{i}v_{i}.
\end{align*}

\end_inset

Expanding 
\begin_inset Formula $\left\langle x,T(y)\right\rangle $
\end_inset

 and 
\begin_inset Formula $\left\langle T^{-1}(x),y\right\rangle $
\end_inset

 we get
\begin_inset Formula 
\begin{align*}
\left\langle x,T(y)\right\rangle  & =\left\langle \sum a_{i}T(v_{i}),T\left(\sum b_{i}v_{i}\right)\right\rangle \\
 & =\left\langle \sum a_{i}T(v_{i}),\sum b_{i}T(v_{i})\right\rangle \\
 & =\sum a_{i}\overline{b_{i}}\\
\left\langle T^{-1}(x),y\right\rangle  & =\left\langle T^{-1}\left(\sum a_{i}T(v_{i})\right),\sum b_{i}v_{i}\right\rangle \\
 & =\sum a_{i}\overline{b_{i}}.
\end{align*}

\end_inset

 
\end_layout

\begin_layout Standard
We should apply abstract results on concrete examples.
\end_layout

\begin_layout Section
Exercise 2.4.9.

\emph on
 AB invertible implies A and B are invertible for square matrices A and
 B
\end_layout

\begin_layout Standard

\emph on
Let A and B be 
\begin_inset Formula $n\times n$
\end_inset

 matrices such that AB is invertible.
 Prove that A and B are invertible.
 Give an example to show that arbitrary matrices A and B need not be invertible
 if AB is invertible.
\end_layout

\begin_layout Standard
Proof.
 The columns of AB are of the form 
\begin_inset Formula $\left[Ab_{1}\cdots Ab_{n}\right]$
\end_inset

 where 
\begin_inset Formula $b_{i}$
\end_inset

 are the columns of 
\begin_inset Formula $B.$
\end_inset

 Since AB is invertible, its columns are linearly independent.
 By the rank-nullity theorem (
\begin_inset Formula $\dim N_{A}+\dim R_{A}=\dim V=n$
\end_inset

), we have 
\begin_inset Formula $\dim R_{A}=n,$
\end_inset

 so 
\begin_inset Formula $\dim N_{A}=0,$
\end_inset

 and T is invertible.
 This also means the 
\begin_inset Formula $b_{i}$
\end_inset

 are linearly independent, so 
\begin_inset Formula $B$
\end_inset

 is invertible.
\end_layout

\begin_layout Section
Exercise 2.4.10.
 
\emph on
One-sided inverse is a two-sided inverse
\end_layout

\begin_layout Standard

\emph on
Let A and B be 
\begin_inset Formula $n\times n$
\end_inset

 matrices s.t.
 
\begin_inset Formula $AB=I_{n}.$
\end_inset

 (a) Use previous to conclude that A and B are invertible.
 (b) Prove 
\begin_inset Formula $A=B^{-1}$
\end_inset

 and 
\begin_inset Formula $B=A^{-1},$
\end_inset

 i.e.
 for square matrices, a one-sided inverse is a two-sided inverse.
\end_layout

\begin_layout Standard
Proof.
 (a) By previous, A and B are invertible.
 (b) Multiply on the left by 
\begin_inset Formula $A^{-1}$
\end_inset


\begin_inset Formula 
\[
\begin{aligned}AB & =I\\
A^{-1}AB & =A^{-1}\\
B & =A^{-1}.
\end{aligned}
\]

\end_inset

Similarly for the other one.
\end_layout

\begin_layout Section
Corollary 6.18.
 Selfadjoint and orthogonal iff orthonormal basis of eigenvectors with eigenvalu
es of absolute value 1
\end_layout

\begin_layout Standard
Corollary
\emph on
.
 Let 
\begin_inset Formula $TnV\mathbf{R}\left\langle \right\rangle .$
\end_inset

 Then V has an orthonormal basis of eigenvectors of T with corresponding
 eigenvalues of absolute value 1 iff T is both selfadjoint and orthogonal.
\end_layout

\begin_layout Standard

\emph on
Proof.
 
\begin_inset Formula $\left(\implies\right)$
\end_inset

 
\emph default
Suppose 
\begin_inset Formula $\beta=\left\{ v_{i}\right\} $
\end_inset

 is an orthonormal basis of eigenvectors of T with corresponding eigenvalues
 of absolute value 1.
 By Theorem 6.17 T is selfadjoint.
 Let 
\begin_inset Formula $x=\sum a_{i}v_{i}.$
\end_inset

 We want to show T is orthogonal, i.e.
 
\begin_inset Formula $\left|\left|T(x)\right|\right|=\left|\left|x\right|\right|:$
\end_inset

 
\begin_inset Formula 
\[
\left|\left|T(x)\right|\right|^{2}=\left\langle T(x),T(x)\right\rangle =\left\langle \sum a_{i}T(v_{i}),\sum a_{i}T(v_{i})\right\rangle =\sum a_{i}^{2}=\left|\left|x\right|\right|
\]

\end_inset

because the 
\begin_inset Formula $T(v_{i})$
\end_inset

's are orthonormal, thanks to a lemma we'll prove below.
\end_layout

\begin_layout Standard
\begin_inset Formula $(\impliedby)$
\end_inset

 Suppose T is selfadjoint and orthogonal.
 By Theorem 6.17 V has an orthonormal basis 
\begin_inset Formula $\beta=\left\{ v_{i}\right\} $
\end_inset

 of eigenvectors of T.
 WTS 
\begin_inset Formula $\left|\lambda_{i}\right|=1.$
\end_inset

 We have 
\begin_inset Formula $T(v_{i})=\lambda_{i}v_{i},$
\end_inset

 so
\begin_inset Formula 
\begin{align*}
\left|\left|T(v_{i})\right|\right|=\left\langle T(v_{i}),T(v_{i})\right\rangle  & =\left\langle \lambda_{i}v_{i},\lambda_{i}v_{i}\right\rangle =\lambda_{i}^{2}\left\langle v_{i},v_{i}\right\rangle =\lambda_{i}^{2}\left|\left|v_{i}\right|\right|\\
1 & =\lambda_{i}^{2},
\end{align*}

\end_inset

because T is orthogonal.
 Therefore 
\begin_inset Formula $\left|\lambda_{i}\right|=1.$
\end_inset

 [NOTE.
 We could've written the previous equation using norms instead of inner
 products: 
\begin_inset Formula $\left|\left|T(v_{i})\right|\right|=\left|\left|\lambda_{i}v_{i}\right|\right|=\left|\lambda_{i}\right|\left|\left|v\right|\right|.$
\end_inset

]
\end_layout

\begin_layout Section
Corollary 6.18.1.
 Unitary iff orthonormal basis of eigenvectors with eigenvalues of absolute
 value 1
\end_layout

\begin_layout Standard
Corollary
\emph on
.
 Let 
\begin_inset Formula $TnV\mathbf{C}\left\langle \right\rangle .$
\end_inset

 Then V has an orthonormal basis of eigenvectors of T with corresponding
 eigenvalues of absolute value 1 iff T is unitary.
\end_layout

\begin_layout Standard

\emph on
Proof similar to the real case.
\end_layout

\begin_layout Section
Lemma *6.18.
 Orthonormal basis of eigenvectors with eigenvalues of absolute value 1
 implies T maps orthonormal basis to orthonormal basis
\end_layout

\begin_layout Standard
Lemma
\emph on
.
 Let 
\begin_inset Formula $TnV\mathbf{R}\left\langle \right\rangle .$
\end_inset

 If V has an orthonormal basis 
\begin_inset Formula $\beta$
\end_inset

 of eigenvectors with eigenvalues of absolute value 1, then 
\begin_inset Formula $T(\beta)$
\end_inset

 is also an orthonormal basis.
\end_layout

\begin_layout Standard

\emph on
Proof.
 
\emph default
Let 
\begin_inset Formula $\beta=\left\{ v_{i}\right\} .$
\end_inset

 Then 
\begin_inset Formula 
\[
\left\langle T(v_{i}),T(v_{j})\right\rangle =\left\langle \lambda_{i}v_{i},\lambda_{j}v_{j}\right\rangle =\lambda_{i}\lambda_{j}\delta_{ij}=\begin{cases}
0 & \textrm{if }i\neq j\\
1 & \textrm{if }i=j.
\end{cases}
\]

\end_inset

Therefore the 
\begin_inset Formula $T(v_{i})$
\end_inset

's are orthonormal and form an orthonormal basis.
\end_layout

\begin_layout Section
Definition 6.18.
 Reflection about a line in 
\begin_inset Formula $R^{2}$
\end_inset


\end_layout

\begin_layout Standard

\emph on
Let L be a one dimensional subspace of 
\begin_inset Formula $R^{2}.$
\end_inset

 We may view L as a line in the plane through the origin.
 A linear operator T on 
\begin_inset Formula $R^{2}$
\end_inset

 is called a reflection of 
\begin_inset Formula $R^{2}$
\end_inset

 about L if 
\begin_inset Formula $T(x)=x$
\end_inset

 for all 
\begin_inset Formula $x\in L$
\end_inset

 and 
\begin_inset Formula $T(x)=-x$
\end_inset

 for all 
\begin_inset Formula $x\in L^{\perp}.$
\end_inset

 
\end_layout

\begin_layout Standard
T is an orthogonal operator: let 
\begin_inset Formula $v_{1}\in L,v_{2}\in L^{\perp}$
\end_inset

 with length 1.
 Then 
\begin_inset Formula $T(v_{1})=v_{1}$
\end_inset

 and 
\begin_inset Formula $T(v_{2})=-v_{2},$
\end_inset

 thus 
\begin_inset Formula $v_{i}$
\end_inset

 are eigenvectors with eigenvalues 1 and 
\begin_inset Formula $-1.$
\end_inset

 By Corollary 6.18 T is orthogonal.
 We can also see that 
\begin_inset Formula $\beta=\left\{ v_{i}\right\} $
\end_inset

 is an orthonormal basis for V, as is 
\begin_inset Formula $T(\beta)=\left\{ T(v_{i})\right\} .$
\end_inset

 
\end_layout

\begin_layout Section
Example 6.5.5.
 Matrix representation of a reflection in 
\begin_inset Formula $R^{2}$
\end_inset

 
\end_layout

\begin_layout Standard

\emph on
Let T be a reflection about a line through the origin in 
\begin_inset Formula $R^{2},$
\end_inset

 let 
\begin_inset Formula $\beta$
\end_inset

 be the standard basis for 
\begin_inset Formula $R^{2},$
\end_inset

 and let 
\begin_inset Formula $A=\left[T\right]_{\beta}.$
\end_inset

 Then 
\begin_inset Formula $T=L_{A}.$
\end_inset

 Since 
\emph default
[Corollary 6.18.2.]
\emph on
 T is an orthogonal operator and 
\begin_inset Formula $\beta$
\end_inset

 is an orthonormal basis, 
\begin_inset Formula $A$
\end_inset

 is an orthogonal matrix.
 We want to know what A looks like.
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $\alpha$
\end_inset

 be the angle from the positive x-axis to L.
 Let 
\begin_inset Formula $v_{1}=\left(\cos\alpha,\sin\alpha\right)$
\end_inset

 and 
\begin_inset Formula $v_{2}=\left(-\sin\alpha,\cos\alpha\right).$
\end_inset

 Then 
\begin_inset Formula $\left|\left|v_{1}\right|\right|=\left|\left|v_{2}\right|\right|=1,v_{1}\in L,v_{2}\in L^{\perp}.$
\end_inset

 Hence 
\begin_inset Formula $\gamma=\left\{ v_{1},v_{2}\right\} $
\end_inset

 is an orthonormal basis for 
\begin_inset Formula $R^{2}.$
\end_inset

 Since 
\begin_inset Formula $T(v_{1})=v_{1},T(v_{2})=-v_{2},$
\end_inset

 we have 
\begin_inset Formula 
\[
\left[T\right]_{\gamma}=\begin{bmatrix}1 & 0\\
0 & -1
\end{bmatrix}.
\]

\end_inset

Let 
\begin_inset Formula 
\[
Q=\begin{bmatrix}\cos\alpha & -\sin\alpha\\
\sin\alpha & \cos\alpha
\end{bmatrix}
\]

\end_inset

be the change of coordinates matrix from the standard basis to 
\begin_inset Formula $\gamma.$
\end_inset

 By Corollary 2.23, 
\begin_inset Formula 
\[
\begin{aligned}A & =Q\left[T\right]_{\gamma}Q^{-1}\\
 & =\begin{bmatrix}\cos2\alpha & \sin2\alpha\\
\sin2\alpha & -\cos2\alpha
\end{bmatrix}.
\end{aligned}
\]

\end_inset


\end_layout

\begin_layout Section
Definition 6.18.1.
 Orthogonal and unitary matrices
\end_layout

\begin_layout Standard
Definition.
 
\emph on
A square matrix A is called an orthogonal matrix if 
\begin_inset Formula $A^{t}A=AA^{t}=I$
\end_inset

 and unitary if 
\begin_inset Formula $A^{*}A=AA^{*}=I.$
\end_inset

 
\end_layout

\begin_layout Section
Corollary 6.18.1.1 Square matrix is unitary / orthogonal iff its rows and columns
 form orthonormal bases for 
\begin_inset Formula $F^{n}.$
\end_inset


\end_layout

\begin_layout Standard

\emph on
\begin_inset Formula $AA^{*}=I$
\end_inset

 is equivalent to the statement that the rows of A form an orthonormal basis
 for 
\begin_inset Formula $F^{n},$
\end_inset


\emph default
 
\emph on
because 
\begin_inset Formula 
\[
AA^{*}=I=\begin{bmatrix}A_{1}\\
\vdots\\
A_{n}
\end{bmatrix}\begin{bmatrix}\overline{A_{1}^{t}} & \cdots & \overline{A_{n}^{t}}\end{bmatrix},
\]

\end_inset

and so 
\begin_inset Formula 
\[
\left\langle A_{i},A_{j}\right\rangle =A_{i}\overline{A_{j}^{t}}=\delta_{ij}.
\]

\end_inset

Similarly the condition 
\begin_inset Formula $A^{*}A=I$
\end_inset

 is equivalent to the statement that the columns of A form an orthonormal
 basis for 
\begin_inset Formula $F^{n}.$
\end_inset

 Therefore a square matrix is orthogonal iff its rows and columns form orthonorm
al bases for 
\begin_inset Formula $F^{n}.$
\end_inset


\end_layout

\begin_layout Section
Corollary 6.18.2.
 Operator is unitary / orthogonal iff its matrix under orthonormal basis
 is unitary / orthogonal
\end_layout

\begin_layout Standard

\emph on
Let 
\begin_inset Formula $TnV.$
\end_inset

 By Theorem 6.10, T is unitary / orthogonal iff 
\begin_inset Formula $\left[T\right]_{\beta}$
\end_inset

 is unitary / orthogonal for some orthonormal basis 
\begin_inset Formula $\beta$
\end_inset

 for V.
\end_layout

\begin_layout Section
Note 6.18.3.
 Unitary / orthogonal equivalence by conjugation: 
\begin_inset Formula $A=Q^{-1}DQ.$
\end_inset

 
\end_layout

\begin_layout Standard
For a complex normal [R selfadjoint/symmetric] matrix A, there exists an
 orrthonormal basis 
\begin_inset Formula $\beta$
\end_inset

 consisting of eigenvectors of A [Theorem 6.17 and 6.18], so A is diagonalizable
 and is similar to a diagonal matrix D: 
\begin_inset Formula $A=Q^{-1}DQ,$
\end_inset

 where 
\begin_inset Formula $Q$
\end_inset

 is the matrix whose columns are the vectors in 
\begin_inset Formula $\beta$
\end_inset

 [Theorem 2.23].
 Since the columns of Q form an orthonormal basis, by Corollary 6.18.1 Q is
 unitary [orthogonal].
 In this case, we say that A is unitarily / orthogonally equivalent to D.
\end_layout

\begin_layout Section
Definition 6.18.3.
 Unitary / orthogonal equivalence by conjugation
\end_layout

\begin_layout Standard

\emph on
A and B are unitarily / orthogonally equivalent iff there exists a unitary
 / orthogonal matrix P s.t.
 
\begin_inset Formula $A=P^{*}BP.$
\end_inset

 Since P is unitary/orthogonal, we know by 
\emph default
Corollary 6.18.0
\emph on
 that 
\begin_inset Formula $P^{*}=P^{-1}$
\end_inset

, then by Proposition 6.18.1 we also have 
\begin_inset Formula $A=P^{*}BP=P^{-1}BP.$
\end_inset


\end_layout

\begin_layout Section
Ex 6.5.18.
 Unitary / orthogonal equivalence is an equivalence relation on 
\begin_inset Formula $M_{n\times n}(C)$
\end_inset

 and 
\begin_inset Formula $M_{n\times n}(R)$
\end_inset

.
 
\end_layout

\begin_layout Standard

\emph on
Proof.
 
\emph default
We need to show reflexivity, symmetry, and transitivity.
 Reflexivity: A unitarily equivalent to B means 
\begin_inset Formula $A=Q^{-1}BQ,$
\end_inset

 so 
\begin_inset Formula $QAQ^{-1}=B$
\end_inset

 and B u.eq.
 A.
 Symmetry: A u.eq.
 with itself since 
\begin_inset Formula $A=I^{-1}AI.$
\end_inset

 Transitivity: A u.eq.
 B and B u.eq.
 C means 
\begin_inset Formula $A=Q^{-1}BQ$
\end_inset

 and 
\begin_inset Formula $B=P^{-1}CP,$
\end_inset

 therefore 
\begin_inset Formula 
\[
A=Q^{-1}P^{-1}CPQ=(PQ)^{-1}CPQ,
\]

\end_inset

 so A u.eq.
 C.
\end_layout

\begin_layout Section
The ideal state of mathematics: mechanical manipulation of symbols
\end_layout

\begin_layout Standard
You want to develop mathematics to a stage where all you need to do is apply
 some mechanical rule and execute a rote calculation.
 Remove the need to think, and reduce mathematics to programming.
 That might never happen in full, but that's the end goal of any small corner
 of mathematics.
\end_layout

\begin_layout Section
Question.
 What is the link between normal operators and normal subgroups?
\end_layout

\begin_layout Section
Theorem 6.19.
 Normal iff unitarily equivalent to a diagonal matrix.
\end_layout

\begin_layout Standard

\emph on
Let A be a complex 
\begin_inset Formula $n\times n$
\end_inset

 matrix.
 Then A is normal iff A is u.eq.
 to a diagonal matrix.
\end_layout

\begin_layout Standard

\emph on
Proof.
 
\emph default
The forward direction is already proved in Note 6.18.3: if A is normal, then
 it is u.eq.
 to a diagonal matrix D.
 Conversely, suppose that A is u.eq.
 to a diagonal matrix D.
 Then there exists a unitary matrix P s.t.
 
\begin_inset Formula $A=P^{*}DP.$
\end_inset

 
\begin_inset Formula 
\[
AA^{*}=P^{*}DP(P^{*}DP)^{*}=P^{*}DPP^{*}D^{*}P=P^{*}DD^{*}P.
\]

\end_inset

Similarly
\begin_inset Formula 
\[
A^{*}A=P^{*}D^{*}PP^{*}DP=P^{*}D^{*}DP=P^{*}DD^{*}P.
\]

\end_inset

The last equality holds because D is diagonal, hence 
\begin_inset Formula $D^{*}D=DD^{*}.$
\end_inset

 Therefore A is normal.
\end_layout

\begin_layout Section
Theorem 6.20.
 Real symmetric iff orthogonally equivalent to a diagonal matrix.
\end_layout

\begin_layout Standard

\emph on
Let A be a real 
\begin_inset Formula $n\times n$
\end_inset

 matrix.
 Then A is selfadjoint i.e.
 symmetric iff A is orthogonally equivalent to a diagonal matrix D.
\end_layout

\begin_layout Standard

\emph on
Proof.
 
\emph default
The forward direction is already proved in Note 6.18.3.
 Conversely, suppose that A is ortho.
 eq.
 to a diagonal matrix D.
 Then there exists an orthogonal matrix P s.t.
 
\begin_inset Formula $A=P^{T}DP.$
\end_inset

 We want to show that A is symmetric: 
\begin_inset Formula 
\[
A^{T}=(P^{T}DP)^{T}=P^{T}D^{T}P=P^{T}DP=A,
\]

\end_inset

since D is diagonal.
\end_layout

\begin_layout Section
TODO.
 Is R normal the same as R selfadjoint/symmetric?
\end_layout

\begin_layout Standard
In that case we can restate the last two theorems as simply that 
\emph on
A normal iff A un.
 eq.
 diagonal matrix.
\end_layout

\begin_layout Section
Example 6.5.6.
 Diagonalizing a symmetric matrix by an orthogonal matrix
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula 
\[
A=\left(\begin{array}{ccc}
{4} & {2} & {2}\\
{2} & {1} & {2}\\
{2} & {2} & {4}
\end{array}\right).
\]

\end_inset

Since A is symmetric, Theorem 6.20 says that A is orthog.
 eq.
 to a diagonal matrix.
 WTF orthogonal P and diagonal D s.t.
 
\begin_inset Formula $P^{T}AP=D.$
\end_inset


\end_layout

\begin_layout Standard
By Corollary 6.18.1.1, P is orthogonal iff its columns and rows form orthonormal
 bases for 
\begin_inset Formula $R^{3}.$
\end_inset

 To find P, we find an orthonormal basis for V.
 It's easy to show that the eigenvalues of A are 2 and 8 (TODO.
 Find 
\begin_inset Formula $\lambda$
\end_inset

 s.t.
 
\begin_inset Formula $\det(A-\lambda I)=0$
\end_inset

 by expanding the eq into a polynomial eq of degree 3 and solve.) Once we
 know the eigenvalues, we can find the eigenvectors by solving 
\begin_inset Formula $(A-\lambda I)x=0$
\end_inset

 using Gaussian elimination.
 Two eigenvectors corresponding to 2 are 
\begin_inset Formula $\{(-1,1,0),(-1,0,1)\}.$
\end_inset

 This set is not orthogonal, so we apply Gram-Schmidt to obtain the orthogonal
 set 
\begin_inset Formula $\left\{ \left(-1,1,0\right),(1,1,-2)\right\} .$
\end_inset

 An eigenvector for 
\begin_inset Formula $\lambda=8$
\end_inset

 is 
\begin_inset Formula $(1,1,1).$
\end_inset

 Note that it is orthogonal to the two eigenvectors corresponding to 2,
 by Theorem 6.15.
 Normalizing all 3, we get the orthonormal basis for 
\begin_inset Formula $R^{3}$
\end_inset

 consisting of eigenvectors of A
\begin_inset Formula 
\[
\left\{ \frac{1}{\sqrt{2}}(-1,1,0),\frac{1}{\sqrt{6}}(1,1,-2),\frac{1}{\sqrt{3}}(1.1,1)\right\} .
\]

\end_inset

Thus one choice for P is 
\begin_inset Formula 
\[
P=\left(\begin{array}{ccc}
{\frac{-1}{\sqrt{2}}} & {\frac{1}{\sqrt{6}}} & {\frac{1}{\sqrt{3}}}\\
{\frac{1}{\sqrt{2}}} & {\frac{1}{\sqrt{6}}} & {\frac{1}{\sqrt{3}}}\\
{0} & {\frac{-2}{\sqrt{6}}} & {\frac{1}{\sqrt{3}}}
\end{array}\right),\quad\text{ and }\quad D=\left(\begin{array}{ccc}
{2} & {0} & {0}\\
{0} & {2} & {0}\\
{0} & {0} & {8}
\end{array}\right).
\]

\end_inset


\end_layout

\begin_layout Section
Question.
 Suppose P is uni/orthog, and A is normal/selfadjoint.
 Is 
\begin_inset Formula $P^{*}AP$
\end_inset

 always diagonal?
\end_layout

\begin_layout Section
Schur's Theorem 6.21
\end_layout

\begin_layout Standard

\emph on
Let 
\begin_inset Formula $A\in M_{n\times n}(F)$
\end_inset

 be a matrix whose characteristic polynomial splits over F.
 If 
\begin_inset Formula $F=C,$
\end_inset

 then A is unitarily eq.
 to a complex upper triangular matrix.
 IF 
\begin_inset Formula $F=R,$
\end_inset

 then A is orthogonally eq.
 to a real upper triangular matrix.
\end_layout

\begin_layout Section
Rigid motions
\end_layout

\begin_layout Standard

\emph on
Let VR.
 A function 
\begin_inset Formula $f:V\longrightarrow V$
\end_inset

 is called a rigid motion if 
\begin_inset Formula 
\[
\|f(x)-f(y)\|=\|x-y\|
\]

\end_inset

for all x, y in V.
\end_layout

\begin_layout Standard
E.g.
 Any orthogonal operator on a finite dimensional reall inner product space
 is a rigid motion, e.g.
 rotations, reflection by a line through the origin.
\end_layout

\end_body
\end_document
