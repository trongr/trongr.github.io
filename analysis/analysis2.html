<!DOCTYPE html>
<html>

<head>
<meta charset="utf-8">
<title>Analysis II</title>
<link rel="stylesheet" href="../css/global.css">

<!-- this config must be before MathJax.js: -->
<script src="../js/mathjax.config.js"></script>
<script src="../js/MathJax/MathJax.js"></script>
<!-- <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js"></script> -->

<script src="../js/jquery-3.1.0.min.js"></script>
<script src="../js/smartquotes.js"></script>
<script src="../js/global.js"></script>

</head>

<body>
<div id="content">

<a href="../index.html">HOME</a>

<h1>Analysis II</h1>
<!--
<img src="images/Paarl Extra 1.jpg">

<div class="epigraph">
    <div class="quote">Let the Hunt begin!</div>
    <div class="author"></div>
</div>-->
<script src="../js/toc.js"></script>
<div id="toc"></div>

<h1>Reference</h1>
<ol>
<li>Spivak's Calculus on Manifolds.</li>
<li>Munkres's Analysis on Manifolds.</li>
</ol>

<h1>Cauchy Schwarz Variation</h1>

<p>
    <b>Proposition.</b> <i>Let $A\in M_{m\times n}(\bR), B\in
M_{n\times p}(\bR).$ Define the norm of $A$ to be $|A| =
\sqrt{\sum_{ij} A_{ij}^2},$ and similarly for $|B|.$ Then

$$|AB| \leq |A||B|.$$</i>
</p>

<p>
    <b>Corollary.</b> <i>If $T:\bR^n\longrightarrow \bR^m$ is linear,
then there is an $M$ s.t. $$|T(h)| \leq M|h|$$ for all $h\in\bR^n.$</i>
</p>

<h1>Metric spaces</h1>

<h3>Definition. Euclidean and sup metrics</h3>

<p>
<i>
The Euclidean distance, also called the $ L^2 $ distance, between two points $ p
= (p_i) $ and $ q = (q_i) $ is

\begin{align*}
\left| p - q \right|_2 = \left| q - p \right|_2
    &= \sqrt { \left( q _ { 1} - p _ { 1} \right) ^ { 2} + \cdots + \left( q _ { n } - p _ { n } \right) ^ { 2} } \\
    &= \sqrt { \sum _ { i = 1} ^ { n } \left( q _ { i } - p _ { i } \right) ^ { 2} }.
\end{align*}

The sup distance between p and q is defined to be

\begin{align*}
\left| p - q \right|_{\infty} = \left| q - p \right|_{\infty}
    &= \sup \{ | p_i - q_i | \}. \\
\end{align*}

The $ L^1 $ distance is given by

\begin{align*}
\left| p - q \right|_1 = \left| q - p \right|_1
    &= \sum _ { i = 1} ^ { n } \left| q _ { i } - p _ { i } \right| .
\end{align*}
</i>
</p>

<h1>Definition. $ \e $-neighbourhoods, open balls, and open cubes</h1>
<p>
<i> Let X, d be a metric space, $ a \in X, $ and $ \e > 0. $ Then the $ \e
$-neighbourhood of a is the set

\begin{align*}
U\left( a ; \e \right) = \left\{ x : d \left( x ,a \right) < \e \right\}
\end{align*}

If $ d $ is the Euclidean metric, then $ U \left( a ; \e \right) $ is called the
open ball, and denoted $ B(a, \e). $ If $ d $ is the sup metric, then U is
called the open cube, and denoted $ C(a, \e). $
</i>
</p>

<h3>Proposition. Relations between open balls and cubes</h3>
<p>
<i>
\begin{align*}
B ( a, \e ) \subset C ( a, \e ) \subset B ( a, \sqrt { n } \e )
\end{align*}
 </i>
</p>
<p>
<i>Proof.</i> Follows from the relations

$$ | x | \leq \| x \| \leq \sqrt { n } | x |. $$
</p>

<h1>Definition. Compact set</h1>

<p>
    <i> Let $ X \subset \bR^n. $ A covering of X is a collection of subsets of $
    \bR^n $ whose union contains X. If each subset is open, we call it an open
    covering. X is called compact if every open covering has a finite
    subcollection that also forms an open cover of X. </i>
</p>

<h1>Compact subsets of $\bR^n$</h1>

<p>
    <b>Theorem.</b> <i>A subset of $\bR^n$ is compact iff it is closed and bounded.</i>
</p>

<p><span>
    <i>Counterexample in arbitrary metric space.</i> Let $\RR^\infty$ be the set
    of all infinite tuples $x = (x_1, x_2, \ldots)$ that end in an infinite
    string of 0's. Define an inner product on $\RR^\infty$ by the rule $\< x, y
    \> = \sum x_i y_i.$ (Note that this is a finite sum.) Let $|x - y| =
    \sqrt{\< x - y, x - y \>}$ be the corresponding metric on $\RR^\infty.$
    Define

    $$e_i = (0,\ldots, 1, \ldots, 0, \ldots)$$

    where $1$ appears in the $i$-th place, and let $X$ be the set of all the
    $e_i$'s. Then $X$ is closed, bounded, and noncompact, since we can find an
    open cover that has no finite subcover: for each $ e_i, $ find a small open
    ball containing only it and no other $ e_j. $
</span></p>

<h3>Corollary 4.4. Every compact subset of $ \bR $ has a largest and smallest
element.</h3>
<p>
    <i>Proof.</i> Since X is compact, it is bounded and closed. Since it is
    bounded, it has a greatest lower bound and a least upper bound. Since it is
    closed, they must belong to X.
</p>

<h1>Extreme value theorem 4.5. Continuous functions preserve compactness.</h1>

<p>
    <i> Let X be a compact subspace of $ \bR^n. $ If $ f: X \longrightarrow
    \bR^n $ is continuous, then $ f(X) $ is a compact subspace of $ \bR^n. $ In
    particular, if $ f: X \longrightarrow \bR $ is continuous, then $ f $ has a
    maximum and minimum value.
    </i>
</p>
<p>
    <i> Proof.</i> Let $ \{ V_{\a} \} $ be an open cover of $ f(X). $ The
    preimages $ f^{-1}(V_{\a}) $ form an open cover of $ X. $ Since X is
    compact, there is a finite subcover, say for $ \a = \a_1, \ldots, \a_k. $
    Then $\{ V_{\a_1}, \ldots, V_{\a_k} \} $ covers $ f(X), $ and $ f(X) $ is
    compact.
</p>
<p>
    If $ f: X \longrightarrow \bR, $ then $ f(X) $ is compact, and it has a
    largest and smallest element by the previous Corollary. These are its max
    and min values.
</p>

<h3>Sequential Compactness</h3>

<p><span>
    <b>Definition.</b> A metric space $X$ is sequentially compact if every
    sequence in $X$ has a convergent subsequence to a point $x \in X.$
</span></p>

<p><span>
    <b>Theorem.</b> <i>A metric space $X$ is compact iff it is sequentially
    compact.</i>
</span></p>

<h3>Lemma. Distance to a subset of $ \bR^n $ is a continuous function</h3>

<p>
<i> Let $ C \subset \bR^n. $ For each $ x \in \bR^n, $ define the distance from $ x $ to C:

$$ d ( \mathbf { x } ,C ) = \inf \{ | \mathbf { x } - \mathbf { c } | ; \mathbf { c } \in C \}. $$

Then $ d $ is continuous.
 </i>
</p>

<p>
<i>Proof.</i> Let $ c \in C, x ,y \in \mathbb { R } ^ { n }. $

\begin{align*}
d(x, C) - | x - y | &\leq | x - c | - | x - y | \\
    &\leq | y - c | \text{ by reverse triangle inequality } \\
    &\leq d(y, C) \\
d(x, C) - d(y, C) &\leq | x - y |.
\end{align*}

Since $d(x, C) \longrightarrow d(y, C) $ as $ x \longrightarrow y, $ $ d $ is
continuous.
</p>

<h2>The $\e$-neighbourhood Theorem 4.6. Let X be a compact subset of $\RR^n,$
and let $U$ be an open subset of $\RR^n$ containing X. Then there is an $\e > 0$
s.t. the $\e$-neighbourhood of X (in either Euclidean or sup metric) is
contained in U.</h2>

<p>
<i>Proof.</i> The $\e$-neighbourhood of X in the Euclidean metric is contained
in the $\e$-neighbourhood in the sup metric [<i> Recall $ B ( a, \e ) \subset C
( a, \e ) \subset B ( a, \sqrt { n } \e ) $ </i>], so it's enough to deal with
the latter. [ <i> This proof doesn't actually use the fact that it's a sup
metric though. </i> ]
</p>

<p>
Define $ f: X \longrightarrow \bR $ by

$$ f ( \mathbf { x } ) = d \left( \mathbf { x } ,\mathbf { R } ^ { n } - U \right). $$

Then $ f $ is continuous by the previous Lemma. Let $ x \in X. $ Then some $ \d
$-neighbourhood of $ x $ is contained in U, since U is open. Therefore $ f(x)
\geq \d > 0 $ for all $ x \in X. $ Because X is compact, $ f $ has a minimum
value $ \e. $ Since $ f > 0, $ $ \e > 0. $ Therefore every point $ x \in X $ is
at least a distance $ \e $ from $ \bR^n - U, $ i.e. the $ \e $-neighbourhood of
X is contained in U.
</p>

<h2>Nonexample. Counterexample when X is not compact.</h2>

<p>
Let $ X \subset \bR^2 $ be the $ x $-axis, and let

$$ U = \left\{ ( x ,y ) : y ^ { 2} < 1 / (1 + x ^ { 2}) \right\}. $$

Then there is no $ \e $ s.t. the $ \e $-neighbourhood of X is contained in U.
</p>

<h2>Theorem 4.7. Uniform Continuity: a continuous map on a compact set is
uniformly continuous there. Let X be a compact subspace of $ \bR^m, $ let $ f: X
\longrightarrow \bR^n $ be continuous. Given $ \e > 0 $ there is a $ \d > 0 $
s.t.

$$ | x - y | < \d \implies | f(x) - f(y) | < \e $$

for all $ x, y\in X. $</h2>

<p>
NOTE. Uniform refers to the condition that given a $ \d, $ one $ \e $ can be
found that will satisfy <i> all </i> $ x, y. $
</p>

<p>
<i>Proof.</i> Consider the subspace $ X \times X \subset \bR^m \times \bR^m, $
and within this the subspace

$$ \D = \{ (x, x) : x \in X \}, $$

called the diagonal of $ X \times X. $ $ \D $ is a compact subspace of $ \bR^m
\times \bR^m $ because it is the image of the compact set $ X $ under the
continuous map $ x \longmapsto (x, x). $
</p>
<p>
We prove the theorem first for the Euclidean metric. Let $ g: X \times X
\longrightarrow \bR $ be the function

$$ g(x, y) = \left\lVert f(x) - f(y) \right\rVert. $$

Consider the set of points $ x, y \in X \times X $ for which $ g(x, y) < \e. $
Since $ g $ is continuous, this set is open in $ X \times X. $ [<i> Recall. The
continuous preimage of an open set is open, and $ (- \infty, \e) $ is open in $
\bR. $ </i>] Also it contains the diagonal $ \D, $ since $ g(x, x) = 0. $
Therefore it is equal to the intersection of $ X \times X $ with an open set $ U
\subset \bR^m \times \bR^m $ that contains $ \D. $
</p>

<p>
Compactness of $ \D $ implies that for some $ \d $ the $ \d $-neighbourhood of $
\D $ is contained in U [<i> Recall. The $\e$-neighbourhood Theorem 4.6. </i>]
This is the $ \d $ we're looking for. For if $ x, y\in X $ with $
\left\lVert x - y \right\rVert < \d,
$ then

$$
\| (  x , y ) - (  y , y ) \| = \| (  x -  y , 0) \| = \|  x -  y \| < \delta
$$

so that $ (x, y) $ belongs to the $ \d $-neighbourhood of $ \D, $ and $ (x, y) $
belongs to U, hence $ g(x, y) = \left\lVert f(x) - f(y) \right\rVert < \e, $ as
desired.
</p>

<p>
The proof for sup norm is similar. Alternatively, note that if $
| x - y | < \d / \sqrt{n},
$ then $
\left\lVert x - y \right\rVert < \d,
$ hence

$$
| f(x) - f(y) | \leq \left\lVert f(x) - f(y) \right\rVert < \e.
$$
</p>

<h1>Definition. Lipschitz continuity</h1>

<p>
<i> A function $ f: X \subset \bR^m \longrightarrow \bR^n $ is called Lipschitz
continuous with Lipschitz constant K if for every pair $ x, y\in X $ we have

$$
\left\lVert f(x) - f(y) \right\rVert \leq K \left\lVert x - y \right\rVert.
$$ </i>
</p>

<h3>Corollary. Lipschitz continuity $ \implies $ Uniform continuity.</h3>

<p>
<i>Proof.</i> Let $ f: X \longrightarrow \bR^n $ be a Lipschitz continuous
function and let K be its Lipschitz constant. $ \e > 0. $ We want to find $ \d $
s.t.

$$
\left\lVert x - y \right\rVert < \d \implies \left\lVert f(x) - f(y) \right\rVert < \e
$$

for all $ x, y\in X. $ Let $ \d = \frac{\e}{K}. $ Then for $
x, y
$ s.t.

$$
\left\lVert x - y \right\rVert < \d = \frac{\e}{K},
$$

we have

$$
\left\lVert f(x) - f(y) \right\rVert \leq K \left\lVert x - y \right\rVert < \e,
$$

and $ f $ is uniformly continuous.
</p>

<h3>Example. $ \sin, \cos $ are Lipschitz continuous.</h3>

<h3>Converse counterexample. $ f(x) = \sqrt{x} $ is uniformly continuous but is
not Lipschitz continuous on $ (0, \infty) $</h3>

<p>
<i>Proof.</i> Clearly $ f $ is not Lipschitz continuous on $ (0, \infty) $
because $ f $ has unbounded derivative at 0. To show uniform continuity, let $
\d = \e^2. $ We want to show that

$$
\left\lVert \sqrt{x} - \sqrt{y} \right\rVert \leq_? \sqrt{\left\lVert x - y \right\rVert} < \sqrt{\d} = \e.
$$

By symmetry, we may assume that $ x \geq y. $ Now

\begin{align*}
\sqrt{x} - \sqrt{y} &\leq_? \sqrt{x - y} \\
(\sqrt{x} - \sqrt{y})^2 &\leq_? x - y \\
x - 2 \sqrt{xy} + y &\leq_? x - y \\
2y &\leq_? 2 \sqrt{xy}, \\
\end{align*}

which is true since we assumed $ x \geq y. $
</p>

<h3>Theorem. A function with bounded first derivative is uniformly
continuous.</h3>

<h3>Theorem. A continuously differentiable function is Lipschitz continuous</h3>

<h3>Corollary. Continuously differentiable $ \implies $ Lipschitz continuous $
\implies $ Uniformly continuous </h3>

<h3>Theorem. A function $f:\bR^n\longrightarrow \bR^m$
is continuous iff preimages of open sets are open.</h3>

<h2>Theorem. A continuous function $f:A \subset \bR^n \longrightarrow \bR^m$
maps compact sets to compact sets.</h2>

<h1>Connected Spaces</h1>

<p><span>
    <b>Definition.</b> <i>A metric space X is said to be connected if X cannot
    be written as the union of two disjoint nonempty sets A and B, each of which
    is open in X.</i>
</span></p>

<p><span>
    <b>Theorem.</b> <i>The closed interval $[a, b]\subset \RR$ is connected.</i>
</span></p>

<h2>Intermediate Value Theorem 4.11. Let X be connected. If $f: X \longrightarrow Y$
is continuous, then $f(X)$ is a connected subspace of Y. In particular, if $f: X
\longrightarrow \RR$ is continuous, and $f(x_0) < r < f(x_1)$ for some $x_0, x_1
\in X,$ then $f(x) = r$ for some $x \in X.$</h2>

<h3>Exercise 1.4.4. The open and closed balls and rectangles in $\RR^n$ are
convex</h3>

<p><span>
<i>Proof for open ball $B(0; 1).$</i> Let $a, b \in B(0; 1),$ and let $x =
ta + (1 - t)b$ for $t\in[0, 1].$ Then

\begin{align*}
|ta + (1 - t)b| &\leq |ta| + |(1 - t)b| \\
                &= t|a| + (1 - t)|b| \\
                &< t + (1 - t) \\
                &= 1.
\end{align*}

Therefore $x \in B$ and $B$ is convex.
</span></p>

<h1>Differentiation</h1>

<p>
Recall the derivative of a single-variable function: let $ A \subset \bR $
contain a neighbourhood of a point $ a, $ and let $ \phi: A \longrightarrow \bR.
$
</p>

<h3>Define the derivative of $ \phi $ at $ a $ to be the limit

$$
\phi'(a) = \lim_{t\to 0} \frac{\phi(a + t) - \phi(a)}{t}
$$

if it exists.</h3>

<h3>Definition. Directional derivative</h3>

<h3>
Let $ f: A \subset \bR^m \longrightarrow \bR^n, $ let A contain a neighbourhood
of $ a, $ and $ 0 \neq u \in \bR^m. $ Then we define the directional derivative
of $ f $ at $ a $ along $ u $ to be the limit

$$
f'(a; u) = \lim_{t\to 0} \frac{f(a + tu) - f(a)}{t}
$$

if it exists.
</h3>

<h3>Example. Directional derivative of $ f(x_1, x_2) = x_1 x_2 $</h3>

<p>
Let $ f: \bR^2 \longrightarrow \bR $ be the function $ f(x_1, x_2) = x_1 x_2. $
Let $ a = (a_1, a_2), u = (1, 0). $ Then

\begin{align*}
f'(a; u) &= \lim_{t\to 0} \frac{f(a + tu) - f(a)}{t} \\
    &= \lim_{t\to 0} \frac{f(a_1 + t, a_2) - f(a_1, a_2)}{t} \\
    &= \lim_{t\to 0} \frac{(a_1 + t) a_2 - a_1 a_2}{t} \\
    &= \lim_{t\to 0} \frac{t a_2}{t} \\
    &= a_2.
\end{align*}
</p>

<h3>NOTE. Existence of all Directional derivatives doesn't imply continuity, nor
that composites of functions with all directional derivatives have all
directional derivatives.</h3>

<h3>Definition. Reformulation of the derivative for the single-variable case:
Let $ f: A \subset \bR \longrightarrow \bR, $ let $ A $ contain a neighbourhood
of $ a. $ We say that $ f $ is differentiable at $ a $ if there exists a number
$ \lambda $ s.t.

$$
\frac{f(a + t) - f(a) - \lambda t}{t} \longrightarrow 0
$$

as $ t \longrightarrow 0. $
</h3>

<p>
If $ \lambda $ exists, we denote it by $ f'(a). $ By Definition, $ \lambda $
approximates the slope of $ f $ at $ a, $ and $ \lambda t $ approximates the
increment $ f(a + t) - f(a) $ near $ a. $
</p>

<h1>Definition. Analogous definition of the derivative in the general case: Let
$ f: A \subset \bR^m \longrightarrow \bR^n, $ let $ A $ contain a neighbourhood
of $ a. $ We say that $ f $ is differentiable at $ a $ if there exists an $ n
\times m $ matrix B s.t.

$$
\frac{f(a + h) - f(a) - Bh}{| h |} \longrightarrow 0
$$

as $ h \longrightarrow 0. $
</h1>

<p>
If $ B $ exists, we call it the derivative of $ f $ at $ a, $ and denote it by
$ Df(a). $
</p>

<h3>Proposition. If B exists, then it is unique, so we can denote it by $ Df(a)
$</h3>

<p>
<i>Proof.</i> Suppose C is another matrix that satisfies

$$
\frac{f(a + h) - f(a) - Ch}{| h |} \longrightarrow 0
$$

as $ h \longrightarrow 0. $ Subtracting, we get

$$
\frac{(B - C)h}{| h |} \longrightarrow 0.
$$

Let $ u \neq 0 $ be a fixed vector, and let $ h = tu $ for $ t \in \bR. $ Then

$$
\frac{(B - C)tu}{| tu |} = \frac{(B - C)u}{| u |} \longrightarrow 0.
$$

Therefore we must have $ B - C = 0. $
</p>

<h3>Example. Derivative of affine transformations: Let $ f: \bR^m
\longrightarrow \bR^n $ be the function $ f(x) = Bx + b. $ Then $ f $ is
differentiable and $ Df(a) = B $ for all $ a. $</h3>

<p>
<i>Proof.</i>

$$
f(a + h) - f(a) - Bh = B(a + h) + b - (Ba + b) - Bh = 0,
$$

so the quotient in the definition of the derivative vanishes identically.
</p>

<p>NOTE. This definition is nice because it implies known properties of the
derivative in the single variable case</p>




</div>
</body>
</html>